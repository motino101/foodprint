# -*- coding: utf-8 -*-
"""Copy of Image_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V0noglhNI2ctMP8o7L-Xrvpp3MEADuFM

# Zero-Shot Image Classification

This example shows how [SentenceTransformers](https://www.sbert.net) can be used to map images and texts to the same vector space. 

We can use this to perform **zero-shot image classification** by providing the names for the labels.

As model, we use the [OpenAI CLIP Model](https://github.com/openai/CLIP), which was trained on a large set of images and image alt texts.


The images in this example are from [Unsplash](https://unsplash.com/).
"""

# !pip install sentence-transformers
# !pip install --upgrade pip
# !pip install openai
# !pip install pillow
# import torch


from sentence_transformers import SentenceTransformer, util
import PIL
from PIL import Image
import glob
import torch
import pickle
import zipfile
from IPython.display import display
from IPython.display import Image as IPImage
import os
from tqdm.autonotebook import tqdm
import torch
import pandas as pd
import openai
openai.api_key = "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"

# We use the original CLIP model for computing image embeddings and English text embeddings
en_model = SentenceTransformer('clip-ViT-B-32')

# We download some images from our repository which we want to classify
img_names = ['spag.jpg'] # TO DO: add image
url = 'https://github.com/UKPLab/sentence-transformers/raw/master/examples/applications/image-search/'
for filename in img_names:
    if not os.path.exists(filename):
        util.http_get(url+filename, filename)

# And compute the embeddings for these images
img_emb = en_model.encode([Image.open(filepath) for filepath in img_names], convert_to_tensor=True)

# This code downloads some image files from a specific URL and saves them in the local directory.
# The image filenames are listed in the img_names variable.
# The code then uses an English language model (en_model) to compute embeddings for these images. It reads each image file using the Image.open() function from the PIL module and passes the resulting image objects to the en_model.encode() function to compute the embeddings.
# The resulting embeddings are stored in the img_emb variable as a tensor. The tensor is constructed using the convert_to_tensor=True argument which creates a tensor from a list of arrays, where each array is the embedding for an image.
# Note that this code assumes that the English language model is already defined and imported, and it is capable of encoding images.

# Then, we define our labels as text. Here, we use 4 labels
# labels = ['dog', 'cat', 'Paris at night', 'Paris']

# Load the CSV file into a Pandas DataFrame
df = pd.read_csv('food-list.csv')

# Extract the first column and store it in a new variable, labels
labels = df.iloc[:, 0].tolist()

# And compute the text embeddings for these labels
en_emb = en_model.encode(labels, convert_to_tensor=True)

# Now, we compute the cosine similarity between the images and the labels
cos_scores = util.cos_sim(img_emb, en_emb)

# Then we look which label has the highest cosine similarity with the given images
pred_labels = torch.argmax(cos_scores, dim=1)



# Finally we output the images + labels
for img_name, pred_label in zip(img_names, pred_labels):
    display(IPImage(img_name, width=200))
    print("Predicted label:", labels[pred_label])
    print("\n\n")

food_item = labels[pred_label];
prompt = "What is the carbon footprint of " + food_item + " in kg based on scientific estimates.";
response = openai.Completion.create(
    engine="text-davinci-002",
    prompt=prompt,
    temperature=0.5,
    max_tokens=50,
    n=1,
    stop=None,
    frequency_penalty=0,
    presence_penalty=0
)

print(response.choices[0].text)

# Carbon offsets:

#We use Cool Effect's cost of carbon offsets: (1 Tonne = $14.62 USD). Find more here: https://www.cooleffect.org/travel-offset
import re
pollution_Numericamount = ''.join(c for c in response.choices[0].text if (c.isdigit() or c == "."))
pollution_Numericamount = pollution_Numericamount.rstrip(pollution_Numericamount[-1])

calculated_Cost = float(pollution_Numericamount) * 0.00110231 * 14.62
print("the cost of offsetting this meal is: $" + str(round(calculated_Cost,3)) + ".")